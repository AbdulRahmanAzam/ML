{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa67885a-57c6-4159-9989-78b2e6030b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all libraries installed successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"all libraries installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64a7a74-c01a-4b83-9307-16ddf7a7ae9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                                                                               Non-Null Count    Dtype \n",
      "---  ------                                                                                                               --------------    ----- \n",
      " 0   0                                                                                                                    1599999 non-null  int64 \n",
      " 1   1467810369                                                                                                           1599999 non-null  int64 \n",
      " 2   Mon Apr 06 22:19:45 PDT 2009                                                                                         1599999 non-null  object\n",
      " 3   NO_QUERY                                                                                                             1599999 non-null  object\n",
      " 4   _TheSpecialOne_                                                                                                      1599999 non-null  object\n",
      " 5   @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n",
      "None\n",
      "                  0    1467810369\n",
      "count  1.599999e+06  1.599999e+06\n",
      "mean   2.000001e+00  1.998818e+09\n",
      "std    2.000001e+00  1.935757e+08\n",
      "min    0.000000e+00  1.467811e+09\n",
      "25%    0.000000e+00  1.956916e+09\n",
      "50%    4.000000e+00  2.002102e+09\n",
      "75%    4.000000e+00  2.177059e+09\n",
      "max    4.000000e+00  2.329206e+09\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(r\"tweets.csv\", encoding='latin-1')\n",
    "display(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb7fe5f-cc28-46d7-a157-4be4b951ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    0\n",
      "text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# since no columns are given so we are giving the names of the columns\n",
    "cols = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "df = pd.read_csv(r'tweets.csv', encoding='latin-1', names=cols)\n",
    "\n",
    "\n",
    "\n",
    "# now keeping onluy the features and the target variable\n",
    "df = df[['target','text']]\n",
    "\n",
    "# checking for null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c5c050-8340-467f-9fe8-181788d6e75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\azama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\azama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\azama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    tokens = [stemmer.stem(lemmatizer.lemmatize(t)) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc7453a-937b-4514-a5ee-c8532098e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = df['clean_text']\n",
    "y = df['target']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5caed6b-63a8-4fc0-8ea7-192e563536aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction (bag of words)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "XtrainVec = vectorizer.fit_transform(Xtrain)\n",
    "XtestVec = vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1d986e-657e-4a02-8deb-64d7dc421c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78    159494\n",
      "           4       0.79      0.73      0.76    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n",
      "[[127938  31556]\n",
      " [ 42570 117936]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(XtrainVec, ytrain)\n",
    "\n",
    "yPred = model.predict(XtestVec)\n",
    "\n",
    "print(classification_report(ytest, yPred))\n",
    "print(confusion_matrix(ytest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afd41a20-153a-4fd7-a0a8-0aba07413344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is:  [0]\n",
      "the accuracy is:  0.0\n",
      "The probabilities are:  [[0.85754556 0.14245444]]\n"
     ]
    }
   ],
   "source": [
    "# new sample testing \n",
    "sample = 'I can understand this project, it is good as well as bad'\n",
    "sampleVec = vectorizer.transform([sample])\n",
    "print(\"The prediction is: \", model.predict(sampleVec))\n",
    "print(\"the accuracy is: \", model.score(sampleVec, [4]))\n",
    "print(\"The probabilities are: \", model.predict_proba(sampleVec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (TF GPU)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
